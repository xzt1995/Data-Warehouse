## 组件定义
a1.sources = r1 r2 
a1.channels = c1 c2 
a1.sinks = k1 k2

## r1
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.batchSize = 5000
a1.sources.r1.batchDurationMillis = 2000
a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sources.r1.kafka.topics = topic_start

## r2
a1.sources.r2.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r2.batchSize = 5000
a1.sources.r2.batchDurationMillis = 2000
a1.sources.r2.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sources.r2.kafka.topics = topic_event



## c1
a1.channels.c1.type = file
# 存储检查点文件的目录
a1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1
# 文件缓存位置
a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1/
# 单个文件最大大小
a1.channels.c1.maxFileSize = 2146435071
# 最大容量
a1.channels.c1.capacity = 1000000
# 超时时间（秒）
a1.channels.c1.keep-alive = 6

## c2
a1.channels.c2.type = file
a1.channels.c2.checkpointDir = /opt/module/flume/checkpoint/behavior2
a1.channels.c2.dataDirs = /opt/module/flume/data/behavior2/
a1.channels.c2.maxFileSize = 2146435071
a1.channels.c2.capacity = 1000000
a1.channels.c2.keep-alive = 6


## k1
a1.sinks.k1.type = hdfs
# hdfs 路径
a1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_start/%Y-%m-%d 
# 文件前缀名
a1.sinks.k1.hdfs.filePrefix = logstart-
# 以下三个参数的作用是 10秒变一次文件夹名称（根据当前时间）
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = second



## k2
a1.sinks.k2.type = hdfs
a1.sinks.k2.hdfs.path = /origin_data/gmall/log/topic_event/%Y-%m-%d
a1.sinks.k2.hdfs.filePrefix = logevent-
a1.sinks.k2.hdfs.round = true
a1.sinks.k2.hdfs.roundValue = 10
a1.sinks.k2.hdfs.roundUnit = second



## 不要产生大量小文件
# 每一个文件十秒滚动一次
a1.sinks.k1.hdfs.rollInterval = 10
# 每一个文件大小到达128M时滚动文件
a1.sinks.k1.hdfs.rollSize = 134217728
# 不根据传入的event 数量来滚动文件
a1.sinks.k1.hdfs.rollCount = 0

a1.sinks.k2.hdfs.rollInterval = 10
a1.sinks.k2.hdfs.rollSize = 134217728
a1.sinks.k2.hdfs.rollCount = 0

## 控制输出文件是原生文件（采用lzop压缩格式）。
a1.sinks.k1.hdfs.fileType = CompressedStream 
a1.sinks.k2.hdfs.fileType = CompressedStream 

a1.sinks.k1.hdfs.codeC = lzop
a1.sinks.k2.hdfs.codeC = lzop

## 拼装
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

a1.sources.r2.channels = c2
a1.sinks.k2.channel = c2

